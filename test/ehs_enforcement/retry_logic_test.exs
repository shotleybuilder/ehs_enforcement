defmodule EhsEnforcement.RetryLogicTest do
  use ExUnit.Case, async: true
  import ExUnit.CaptureLog

  alias EhsEnforcement.RetryLogic

  describe "exponential backoff retry" do
    test "retries with exponential backoff for retriable errors" do
      attempt_count = Agent.start_link(fn -> 0 end)
      
      result = RetryLogic.with_exponential_backoff(
        fn ->
          Agent.update(attempt_count, &(&1 + 1))
          current_attempt = Agent.get(attempt_count, & &1)
          
          if current_attempt < 3 do
            {:error, %Req.TransportError{reason: :timeout}}
          else
            {:ok, "success"}
          end
        end,
        max_attempts: 3,
        base_delay_ms: 100,
        max_delay_ms: 1000
      )
      
      assert result == {:ok, "success"}
      assert Agent.get(attempt_count, & &1) == 3
      
      Agent.stop(attempt_count)
    end

    test "fails after max attempts with exponential backoff" do
      attempt_count = Agent.start_link(fn -> 0 end)
      
      result = RetryLogic.with_exponential_backoff(
        fn ->
          Agent.update(attempt_count, &(&1 + 1))
          {:error, %Req.TransportError{reason: :timeout}}
        end,
        max_attempts: 3,
        base_delay_ms: 50,
        max_delay_ms: 500
      )
      
      assert {:error, :max_attempts_exceeded} = result
      assert Agent.get(attempt_count, & &1) == 3
      
      Agent.stop(attempt_count)
    end

    test "calculates correct exponential backoff delays" do
      delays = RetryLogic.calculate_backoff_delays(
        base_delay_ms: 100,
        max_delay_ms: 1000,
        max_attempts: 5,
        jitter: false
      )
      
      assert delays == [100, 200, 400, 800, 1000]
    end

    test "applies jitter to backoff delays" do
      delays = RetryLogic.calculate_backoff_delays(
        base_delay_ms: 100,
        max_delay_ms: 1000,
        max_attempts: 3,
        jitter: true
      )
      
      # With jitter, delays should be different on each call and within expected ranges
      delays2 = RetryLogic.calculate_backoff_delays(
        base_delay_ms: 100,
        max_delay_ms: 1000,
        max_attempts: 3,
        jitter: true
      )
      
      assert delays != delays2  # Jitter should make them different
      assert Enum.all?(delays, fn delay -> delay >= 50 and delay <= 150 end)  # Within jitter range for first delay
    end

    test "respects max delay limit in exponential backoff" do
      delays = RetryLogic.calculate_backoff_delays(
        base_delay_ms: 1000,
        max_delay_ms: 2000,
        max_attempts: 5,
        jitter: false
      )
      
      assert delays == [1000, 2000, 2000, 2000, 2000]  # Should cap at max_delay_ms
    end
  end

  describe "linear backoff retry" do
    test "retries with linear backoff" do
      attempt_count = Agent.start_link(fn -> 0 end)
      
      result = RetryLogic.with_linear_backoff(
        fn ->
          Agent.update(attempt_count, &(&1 + 1))
          current_attempt = Agent.get(attempt_count, & &1)
          
          if current_attempt < 2 do
            {:error, :temporary_failure}
          else
            {:ok, "success"}
          end
        end,
        max_attempts: 3,
        delay_ms: 100
      )
      
      assert result == {:ok, "success"}
      assert Agent.get(attempt_count, & &1) == 2
      
      Agent.stop(attempt_count)
    end

    test "calculates correct linear backoff delays" do
      delays = RetryLogic.calculate_linear_delays(
        delay_ms: 500,
        max_attempts: 4
      )
      
      assert delays == [500, 500, 500, 500]
    end
  end

  describe "fibonacci backoff retry" do
    test "retries with fibonacci backoff sequence" do
      attempt_count = Agent.start_link(fn -> 0 end)
      
      result = RetryLogic.with_fibonacci_backoff(
        fn ->
          Agent.update(attempt_count, &(&1 + 1))
          current_attempt = Agent.get(attempt_count, & &1)
          
          if current_attempt < 3 do
            {:error, :temporary_failure}
          else
            {:ok, "success"}
          end
        end,
        max_attempts: 5,
        base_delay_ms: 100,
        max_delay_ms: 2000
      )
      
      assert result == {:ok, "success"}
      assert Agent.get(attempt_count, & &1) == 3
      
      Agent.stop(attempt_count)
    end

    test "calculates correct fibonacci backoff delays" do
      delays = RetryLogic.calculate_fibonacci_delays(
        base_delay_ms: 100,
        max_delay_ms: 1500,
        max_attempts: 6
      )
      
      # Fibonacci sequence: 1, 1, 2, 3, 5, 8 * base_delay_ms
      assert delays == [100, 100, 200, 300, 500, 800]
    end

    test "respects max delay in fibonacci sequence" do
      delays = RetryLogic.calculate_fibonacci_delays(
        base_delay_ms: 200,
        max_delay_ms: 500,
        max_attempts: 6
      )
      
      # Should cap at max_delay_ms when fibonacci exceeds it
      assert delays == [200, 200, 400, 500, 500, 500]
    end
  end

  describe "conditional retry logic" do
    test "retries only on specific error types" do
      attempt_count = Agent.start_link(fn -> 0 end)
      
      result = RetryLogic.with_conditional_retry(
        fn ->
          Agent.update(attempt_count, &(&1 + 1))
          {:error, %Req.TransportError{reason: :timeout}}
        end,
        retry_when: fn
          {:error, %Req.TransportError{reason: :timeout}} -> true
          {:error, %Req.TransportError{reason: :econnrefused}} -> true
          _ -> false
        end,
        max_attempts: 3,
        base_delay_ms: 50
      )
      
      assert {:error, :max_attempts_exceeded} = result
      assert Agent.get(attempt_count, & &1) == 3
      
      Agent.stop(attempt_count)
    end

    test "does not retry on non-retriable errors" do
      attempt_count = Agent.start_link(fn -> 0 end)
      
      result = RetryLogic.with_conditional_retry(
        fn ->
          Agent.update(attempt_count, &(&1 + 1))
          {:error, %Ecto.ConstraintError{constraint: "unique_constraint"}}
        end,
        retry_when: fn
          {:error, %Req.TransportError{}} -> true
          _ -> false
        end,
        max_attempts: 3,
        base_delay_ms: 50
      )
      
      assert {:error, %Ecto.ConstraintError{constraint: "unique_constraint"}} = result
      assert Agent.get(attempt_count, & &1) == 1  # Should only try once
      
      Agent.stop(attempt_count)
    end

    test "retries with custom logic based on error and context" do
      attempt_count = Agent.start_link(fn -> 0 end)
      
      result = RetryLogic.with_context_aware_retry(
        fn ->
          Agent.update(attempt_count, &(&1 + 1))
          current_attempt = Agent.get(attempt_count, & &1)
          
          if current_attempt < 2 do
            {:error, %Req.TransportError{reason: :timeout}}
          else
            {:ok, "success"}
          end
        end,
        context: %{operation: "fetch_cases", agency: :hse, critical: false},
        retry_policy: :api_operations,
        max_attempts: 3
      )
      
      assert result == {:ok, "success"}
      assert Agent.get(attempt_count, & &1) == 2
      
      Agent.stop(attempt_count)
    end
  end

  describe "circuit breaker pattern" do
    test "opens circuit after consecutive failures" do
      # Initialize circuit breaker
      circuit_name = :test_circuit
      RetryLogic.init_circuit_breaker(circuit_name, failure_threshold: 3, timeout_ms: 1000)
      
      # Cause consecutive failures
      Enum.each(1..3, fn _ ->
        RetryLogic.call_with_circuit_breaker(circuit_name, fn ->
          {:error, :service_unavailable}
        end)
      end)
      
      # Circuit should now be open
      result = RetryLogic.call_with_circuit_breaker(circuit_name, fn ->
        {:ok, "should_not_execute"}
      end)
      
      assert result == {:error, :circuit_open}
      
      # Clean up
      RetryLogic.reset_circuit_breaker(circuit_name)
    end

    test "transitions from open to half-open after timeout" do
      circuit_name = :test_timeout_circuit
      RetryLogic.init_circuit_breaker(circuit_name, failure_threshold: 2, timeout_ms: 100)
      
      # Cause failures to open circuit
      Enum.each(1..2, fn _ ->
        RetryLogic.call_with_circuit_breaker(circuit_name, fn ->
          {:error, :service_unavailable}
        end)
      end)
      
      # Wait for timeout
      :timer.sleep(150)
      
      # Should be in half-open state and allow one request
      result = RetryLogic.call_with_circuit_breaker(circuit_name, fn ->
        {:ok, "recovery_test"}
      end)
      
      assert result == {:ok, "recovery_test"}
      
      # Clean up
      RetryLogic.reset_circuit_breaker(circuit_name)
    end

    test "closes circuit after successful recovery" do
      circuit_name = :test_recovery_circuit
      RetryLogic.init_circuit_breaker(circuit_name, failure_threshold: 2, timeout_ms: 50)
      
      # Open circuit
      Enum.each(1..2, fn _ ->
        RetryLogic.call_with_circuit_breaker(circuit_name, fn ->
          {:error, :service_unavailable}
        end)
      end)
      
      # Wait for timeout
      :timer.sleep(100)
      
      # Successful recovery call
      RetryLogic.call_with_circuit_breaker(circuit_name, fn ->
        {:ok, "recovered"}
      end)
      
      # Circuit should be closed and allow normal operation
      result = RetryLogic.call_with_circuit_breaker(circuit_name, fn ->
        {:ok, "normal_operation"}
      end)
      
      assert result == {:ok, "normal_operation"}
      
      # Clean up
      RetryLogic.reset_circuit_breaker(circuit_name)
    end

    test "tracks circuit breaker metrics" do
      circuit_name = :test_metrics_circuit
      RetryLogic.init_circuit_breaker(circuit_name, failure_threshold: 2, timeout_ms: 1000)
      
      # Generate some calls
      RetryLogic.call_with_circuit_breaker(circuit_name, fn -> {:ok, "success"} end)
      RetryLogic.call_with_circuit_breaker(circuit_name, fn -> {:error, :failure} end)
      RetryLogic.call_with_circuit_breaker(circuit_name, fn -> {:error, :failure} end)  # This opens circuit
      RetryLogic.call_with_circuit_breaker(circuit_name, fn -> {:ok, "blocked"} end)  # This should be blocked
      
      metrics = RetryLogic.get_circuit_breaker_metrics(circuit_name)
      
      assert metrics.total_calls == 4
      assert metrics.successful_calls == 1
      assert metrics.failed_calls == 2
      assert metrics.blocked_calls == 1
      assert metrics.state == :open
      
      # Clean up
      RetryLogic.reset_circuit_breaker(circuit_name)
    end
  end

  describe "async retry operations" do
    test "retries async operations with proper task supervision" do
      parent = self()
      
      task = RetryLogic.async_retry(
        fn ->
          send(parent, :attempt)
          {:error, :temporary_failure}
        end,
        max_attempts: 3,
        base_delay_ms: 50,
        on_success: fn result -> send(parent, {:success, result}) end,
        on_failure: fn error -> send(parent, {:failure, error}) end
      )
      
      # Wait for completion
      Task.await(task, 5000)
      
      # Should receive 3 attempt messages and 1 failure message
      attempts = for _ <- 1..3 do
        receive do
          :attempt -> :attempt
        after
          1000 -> :timeout
        end
      end
      assert length(attempts) == 3
      
      assert_receive {:failure, :max_attempts_exceeded}
    end

    test "handles successful async retry" do
      parent = self()
      attempt_count = Agent.start_link(fn -> 0 end)
      
      task = RetryLogic.async_retry(
        fn ->
          Agent.update(attempt_count, &(&1 + 1))
          current_attempt = Agent.get(attempt_count, & &1)
          
          if current_attempt < 2 do
            {:error, :temporary_failure}
          else
            {:ok, "async_success"}
          end
        end,
        max_attempts: 3,
        base_delay_ms: 50,
        on_success: fn result -> send(parent, {:success, result}) end,
        on_failure: fn error -> send(parent, {:failure, error}) end
      )
      
      Task.await(task, 5000)
      
      assert_receive {:success, "async_success"}
      assert Agent.get(attempt_count, & &1) == 2
      
      Agent.stop(attempt_count)
    end
  end

  describe "retry with rate limiting" do
    test "respects rate limits during retry operations" do
      rate_limiter = :test_rate_limiter
      RetryLogic.init_rate_limiter(rate_limiter, max_requests: 2, window_ms: 1000)
      
      attempt_count = Agent.start_link(fn -> 0 end)
      
      result = RetryLogic.with_rate_limited_retry(
        fn ->
          Agent.update(attempt_count, &(&1 + 1))
          current_attempt = Agent.get(attempt_count, & &1)
          
          if current_attempt < 3 do
            {:error, :temporary_failure}
          else
            {:ok, "success"}
          end
        end,
        rate_limiter: rate_limiter,
        max_attempts: 5,
        base_delay_ms: 50
      )
      
      # Should be rate limited and not complete all attempts quickly
      assert {:error, :rate_limited} = result
      
      # Should have tried only up to the rate limit
      assert Agent.get(attempt_count, & &1) <= 2
      
      Agent.stop(attempt_count)
      RetryLogic.cleanup_rate_limiter(rate_limiter)
    end

    test "allows retries after rate limit window expires" do
      rate_limiter = :test_window_limiter
      RetryLogic.init_rate_limiter(rate_limiter, max_requests: 1, window_ms: 100)
      
      # First attempt should work
      result1 = RetryLogic.with_rate_limited_retry(
        fn -> {:ok, "first"} end,
        rate_limiter: rate_limiter,
        max_attempts: 1,
        base_delay_ms: 50
      )
      
      assert result1 == {:ok, "first"}
      
      # Second attempt should be rate limited
      result2 = RetryLogic.with_rate_limited_retry(
        fn -> {:ok, "second"} end,
        rate_limiter: rate_limiter,
        max_attempts: 1,
        base_delay_ms: 50
      )
      
      assert result2 == {:error, :rate_limited}
      
      # Wait for window to expire
      :timer.sleep(150)
      
      # Third attempt should work
      result3 = RetryLogic.with_rate_limited_retry(
        fn -> {:ok, "third"} end,
        rate_limiter: rate_limiter,
        max_attempts: 1,
        base_delay_ms: 50
      )
      
      assert result3 == {:ok, "third"}
      
      RetryLogic.cleanup_rate_limiter(rate_limiter)
    end
  end

  describe "retry policies and configuration" do
    test "applies predefined retry policies" do
      # Test API operations policy
      api_policy = RetryLogic.get_retry_policy(:api_operations)
      
      assert api_policy.max_attempts == 3
      assert api_policy.backoff_type == :exponential
      assert api_policy.base_delay_ms == 1000
      assert api_policy.max_delay_ms == 30_000
      assert api_policy.jitter == true
    end

    test "applies database operations retry policy" do
      db_policy = RetryLogic.get_retry_policy(:database_operations)
      
      assert db_policy.max_attempts == 5
      assert db_policy.backoff_type == :exponential
      assert db_policy.base_delay_ms == 500
      assert db_policy.max_delay_ms == 10_000
      assert db_policy.jitter == false
    end

    test "applies critical operations retry policy" do
      critical_policy = RetryLogic.get_retry_policy(:critical_operations)
      
      assert critical_policy.max_attempts == 10
      assert critical_policy.backoff_type == :fibonacci
      assert critical_policy.base_delay_ms == 100
      assert critical_policy.max_delay_ms == 60_000
      assert critical_policy.circuit_breaker == true
    end

    test "allows custom retry policy configuration" do
      custom_policy = %{
        max_attempts: 7,
        backoff_type: :linear,
        base_delay_ms: 2000,
        max_delay_ms: 2000,
        jitter: false,
        circuit_breaker: false
      }
      
      result = RetryLogic.with_custom_policy(
        fn -> {:error, :always_fails} end,
        custom_policy
      )
      
      assert {:error, :max_attempts_exceeded} = result
    end
  end

  describe "retry logging and monitoring" do
    test "logs retry attempts with structured metadata" do
      log = capture_log(fn ->
        RetryLogic.with_exponential_backoff(
          fn -> {:error, %Req.TransportError{reason: :timeout}} end,
          max_attempts: 2,
          base_delay_ms: 50,
          operation: "test_operation",
          context: %{agency: :hse}
        )
      end)
      
      assert log =~ "Retry attempt"
      assert log =~ "operation=test_operation"
      assert log =~ "agency=hse"
      assert log =~ "attempt=1"
    end

    test "tracks retry metrics for monitoring" do
      RetryLogic.reset_metrics()
      
      # Perform some retries
      RetryLogic.with_exponential_backoff(
        fn -> {:error, :failure} end,
        max_attempts: 3,
        base_delay_ms: 50,
        operation: "test_op"
      )
      
      RetryLogic.with_exponential_backoff(
        fn -> {:ok, "success"} end,
        max_attempts: 3,
        base_delay_ms: 50,
        operation: "test_op"
      )
      
      metrics = RetryLogic.get_retry_metrics()
      
      assert metrics.total_operations == 2
      assert metrics.successful_operations == 1
      assert metrics.failed_operations == 1
      assert metrics.total_attempts == 4  # 3 failed attempts + 1 successful
      assert metrics.by_operation["test_op"].total == 2
    end

    test "generates retry performance report" do
      RetryLogic.reset_metrics()
      
      # Generate various retry scenarios
      Enum.each(1..5, fn _ ->
        RetryLogic.with_exponential_backoff(
          fn -> {:error, :failure} end,
          max_attempts: 2,
          base_delay_ms: 50,
          operation: "failing_op"
        )
      end)
      
      Enum.each(1..3, fn _ ->
        RetryLogic.with_exponential_backoff(
          fn -> {:ok, "success"} end,
          max_attempts: 2,
          base_delay_ms: 50,
          operation: "success_op"
        )
      end)
      
      report = RetryLogic.generate_performance_report()
      
      assert report.total_operations == 8
      assert report.overall_success_rate == 0.375  # 3 successes out of 8 operations
      assert length(report.most_retried_operations) > 0
      assert is_float(report.average_attempts_per_operation)
    end
  end
end